{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDZmp2BO9KnQ"
      },
      "source": [
        "# **Laboratorio 8: Ready, Set, Deploy! üë©‚ÄçüöÄüë®‚ÄçüöÄ**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Oto√±o 2025</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdGqUgwX9pGQ"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Sebasti√°n Acu√±a U.\n",
        "- Nombre de alumno 2: Mart√≠n Guzm√°n S.\n",
        "\n",
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/sebastianacunau/MDS7202-Laboratorios-y-Proyecto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YraSOKrf9yMl"
      },
      "source": [
        "## Temas a tratar\n",
        "\n",
        "- Entrenamiento y registro de modelos usando MLFlow.\n",
        "- Despliegue de modelo usando FastAPI\n",
        "- Containerizaci√≥n del proyecto usando Docker\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Generar una soluci√≥n a un problema a partir de ML\n",
        "- Desplegar su soluci√≥n usando MLFlow, FastAPI y Docker\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98okEzUE8hb"
      },
      "source": [
        "# **Introducci√≥n**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSiuBfGiFlQM"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPn8R-6u877j"
      },
      "source": [
        "\n",
        "\n",
        "Consumida en la tristeza el despido de Renac√≠n, Smapina ha deca√≠do en su desempe√±o, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria p√∫blica de la municipalidad de Maip√∫ se ha contactado con ustedes para que le entreguen una urgente soluci√≥n a este problema (a la vez que dejan a Smapina, al igual que Renac√≠n, sin trabajo üòî).\n",
        "\n",
        "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de m√∫ltiples sensores IOT colocados en diversas ca√±er√≠as, conductos y estanques. Estos sensores se√±alan nueve tipos de mediciones qu√≠micas y m√°s una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
        "\n",
        "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maip√∫ y su intoxicaci√≥n podr√≠a implicar graves problemas para el cierre del curso.\n",
        "\n",
        "Atributos:\n",
        "\n",
        "1. pH value\n",
        "2. Hardness\n",
        "3. Solids (Total dissolved solids - TDS)\n",
        "4. Chloramines\n",
        "5. Sulfate\n",
        "6. Conductivity\n",
        "7. Organic_carbon\n",
        "8. Trihalomethanes\n",
        "9. Turbidity\n",
        "\n",
        "Variable a predecir:\n",
        "\n",
        "10. Potability (1 si es potable, 0 no potable)\n",
        "\n",
        "Descripci√≥n de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aIr6KegWsjS"
      },
      "source": [
        "# **1. Optimizaci√≥n de modelos con Optuna + MLFlow (2.0 puntos)**\n",
        "\n",
        "El objetivo de esta secci√≥n es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimizaci√≥n de los hiperpar√°metros de sus modelos.\n",
        "\n",
        "Como a√∫n no hemos hablado nada sobre `MLFlow` cabe preguntarse: **¬°¬øQu√© !\"#@ es `MLflow`?!**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "## **MLFlow**\n",
        "\n",
        "`MLflow` es una plataforma de c√≥digo abierto que simplifica la gesti√≥n y seguimiento de proyectos de aprendizaje autom√°tico. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, adem√°s de registrar modelos y controlar versiones.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
        "</p>\n",
        "\n",
        "Si bien esta plataforma cuenta con un gran n√∫mero de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
        "1. **Runs**: Registro que constituye la informaci√≥n guardada tras la ejecuci√≥n de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en s√≠ mismo. Dentro de cada `run` podremos acceder a informaci√≥n como los hiperpar√°metros utilizados, las m√©tricas obtenidas, las librer√≠as requeridas y hasta nos permite descargar el modelo entrenado.\n",
        "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o m√°s `runs`. De esta manera, es posible tambi√©n registrar m√©tricas, par√°metros y archivos (artefactos) asociados a cada experimento.\n",
        "\n",
        "### **Todo bien pero entonces, ¬øc√≥mo se usa en la pr√°ctica `MLflow`?**\n",
        "\n",
        "Es sencillo! Considerando un problema de machine learning gen√©rico, podemos registrar la informaci√≥n relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
        "\n",
        "```python\n",
        "#!pip install mlflow\n",
        "import mlflow # importar mlflow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "db = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
        "\n",
        "# Create and train models.\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
        "\n",
        "mlflow.autolog() # registrar autom√°ticamente informaci√≥n del entrenamiento\n",
        "with mlflow.start_run(): #¬†delimita inicio y fin del run\n",
        "    #¬†aqu√≠ comienza el run\n",
        "    rf.fit(X_train, y_train) # train the model\n",
        "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
        "    # aqu√≠ termina el run\n",
        "```\n",
        "\n",
        "Si ustedes ejecutan el c√≥digo anterior en sus m√°quinas locales (desde un jupyter notebook por ejemplo) se dar√°n cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el c√≥digo anterior, se crear√° otra carpeta y no tendr√°n acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
        "\n",
        "```\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Les dejamos tambi√©n algunos comandos √∫tiles:\n",
        "\n",
        "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
        "- `mlflow.log_metric(\"nombre_m√©trica\", m√©trica)`: Les permite registrar una m√©trica *custom* bajo el nombre de \"nombre_m√©trica\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptP_ygr7S04t"
      },
      "source": [
        "## **1.1 Combinando Optuna + MLflow (2.0 puntos)**\n",
        "\n",
        "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **m√°s sabor**. El objetivo de este apartado es simple: automatizar la optimizaci√≥n de los par√°metros de nuestros modelos usando `Optuna` y registrando de forma autom√°tica cada resultado en `MLFlow`.\n",
        "\n",
        "Considerando el objetivo planteado, se le pide completar la funci√≥n `optimize_model`, la cual debe:\n",
        "- **Optimizar los hiperpar√°metros del modelo `XGBoost` usando `Optuna`.**\n",
        "- **Registrar cada entrenamiento en un experimento nuevo**, asegur√°ndose de que la m√©trica `f1-score` se registre como `\"valid_f1\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
        "- **Guardar los gr√°ficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
        "- **Devolver el mejor modelo** usando la funci√≥n `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
        "- **Guardar el c√≥digo en `optimize.py`**. La ejecuci√≥n de `python optimize.py` deber√≠a ejecutar la funci√≥n `optimize_model`.\n",
        "- **Guardar las versiones de las librer√≠as utilizadas** en el desarrollo.\n",
        "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gr√°fico dentro de la carpeta `/plots` creada anteriormente.\n",
        "\n",
        "*Hint: Le puede ser √∫til revisar los par√°metros que recibe `mlflow.start_run`*\n",
        "\n",
        "```python\n",
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "\n",
        "    return best_model\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Paquetes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.22.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.22.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.16.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.55.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.33.1)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.54b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n",
            "Collecting optuna\n",
            "  Using cached optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Collecting colorlog (from optuna)\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Using cached optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.3.0\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install optuna\n",
        "!pip install -U kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Codigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing optimize.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile optimize.py\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "import pickle\n",
        "import optuna\n",
        "import os\n",
        "import kaleido\n",
        "import matplotlib.pyplot as plt\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlflow.exceptions import MlflowException\n",
        "import mlflow.sklearn\n",
        "\n",
        "\n",
        "def get_best_model(experiment_id):\n",
        "    runs = mlflow.search_runs(experiment_id)\n",
        "    best_run = runs.sort_values(\"metrics.valid_f1\", ascending=False).iloc[0]\n",
        "    best_model_id = best_run[\"run_id\"]\n",
        "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
        "    return best_model\n",
        "\n",
        "\n",
        "def optimize_model():\n",
        "  df = pd.read_csv('water_potability.csv')\n",
        "  le = LabelEncoder()\n",
        "  y = le.fit_transform(df['Potability'])\n",
        "  X = df.drop('Potability', axis=1)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "  mlflow.autolog()\n",
        "  nombre_experimento = f\"ESTUDIO DE MODELO DE XGBOOST CON OPTIMIZACION PARA POTABILIDAD DE AGUA \"\n",
        "\n",
        "  try: #CODIGO PARA CHEQUEAR SI EXPERIMENTO YA ESTA CREADO\n",
        "      experimento = mlflow.get_experiment_by_name(nombre_experimento)\n",
        "      if experimento is None:\n",
        "          experimento_id = mlflow.create_experiment(nombre_experimento) #CREACION EXPERIMENTO\n",
        "      else:\n",
        "          experimento_id = experimento.experiment_id\n",
        "  except MlflowException as e:\n",
        "      experimento = mlflow.get_experiment_by_name(nombre_experimento)\n",
        "      if experimento is None:\n",
        "          raise e\n",
        "      experimento_id = experimento.experiment_id\n",
        "\n",
        "\n",
        "\n",
        "  def objetivo(trial):\n",
        "    params = {\n",
        "        \"objective\": \"multi:softmax\",\n",
        "        \"eval_metric\": \"mlogloss\",\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 7),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 300),\n",
        "        \"num_class\": len(le.classes_)\n",
        "    }\n",
        "\n",
        "\n",
        "#inicio run creacion modelo\n",
        "    run_name = f\" Trial de XGBoost # {trial.number}, con max_depth = {params['max_depth']:.4f}, learning_rate = {params['learning_rate']:.4f}\"\n",
        "\n",
        "    with mlflow.start_run(run_name = run_name, experiment_id = experimento_id, nested=True) as run:\n",
        "\n",
        "        model = XGBClassifier(**params)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        mlflow.log_metric(\"valid_f1\", f1) #log de metric f1 score\n",
        "        mlflow.sklearn.log_model(model, \"model\")\n",
        "\n",
        "\n",
        "    return f1\n",
        "\n",
        "  study = optuna.create_study(direction=\"maximize\") #OPTIMIZACION CON OPTUNA\n",
        "  study.optimize(objetivo, n_trials=25) # optimizacion maximizando con la funcion objetivo\n",
        "\n",
        "#Punto 1 CHECK\n",
        "#Punto 2 CHECK\n",
        "  #Inicio run visualizacion y guardado de plots\n",
        "  run_name1 = \"Visualizacion de Optimizacion con Optuna\" #inico 2do run\n",
        "  with mlflow.start_run(run_name = run_name1, experiment_id = experimento_id):\n",
        "    historial_optimizacion = plot_optimization_history(study) #CREACION GRAFICOS CON OPTUNA\n",
        "    plot_coordenadas_paralelas = plot_parallel_coordinate(study)\n",
        "    plot_importancia_parametros  = plot_param_importances(study)\n",
        "\n",
        "    if not os.path.exists(\"plots\"): #CREACION CARPETA PLOTS\n",
        "      os.makedirs(\"plots\")\n",
        "\n",
        "    if 'kaleido' in globals() and kaleido:\n",
        "        historial_optimizacion.write_image(\"plots/historial_optimizacion.png\")\n",
        "        plot_coordenadas_paralelas.write_image(\"plots/plot_coordenadas_paralelas.png\")\n",
        "        plot_importancia_parametros.write_image(\"plots/plot_importancia_parametros.png\")\n",
        "\n",
        "    mlflow.log_artifact(\"plots/historial_optimizacion.png\", artifact_path=\"plots\") #LOG DE IMAGENES\n",
        "    mlflow.log_artifact(\"plots/plot_coordenadas_paralelas.png\", artifact_path= \"plots\")\n",
        "    mlflow.log_artifact(\"plots/plot_importancia_parametros.png\", artifact_path= \"plots\")\n",
        "\n",
        "\n",
        "#PUNTO 3 CHECK\n",
        "\n",
        "\n",
        "  best_model = get_best_model(experimento_id)\n",
        "  run_name2 = \"Mejor Modelo\" #Inicio 3er run\n",
        "  with mlflow.start_run(run_name = run_name2, experiment_id = experimento_id):\n",
        "\n",
        "\n",
        "    if not os.path.exists(\"models\"): #CREACION DE DIRECTORIO MODELS\n",
        "      os.makedirs(\"models\")\n",
        "\n",
        "    with open(\"models/best_model.pkl\", \"wb\") as f:\n",
        "      pickle.dump(best_model, f)\n",
        "\n",
        "    mlflow.log_artifact(\"models/best_model.pkl\", artifact_path=\"models\") #LOG DEL MEJOR MODELO EN DIRECTORIO MODELS\n",
        "\n",
        "\n",
        "\n",
        "#PUNTO 4 CHECK\n",
        "\n",
        "    best_params = best_model.get_params()\n",
        "    feature_importances = best_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    feature_importances = pd.Series(feature_importances, index=feature_names)\n",
        "    feature_importances.sort_values(inplace=True)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(feature_importances.index, feature_importances.values)\n",
        "    plt.xlabel(\"Features\")\n",
        "    plt.ylabel(\"Importance\")\n",
        "    plt.title(\"Feature Importances\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"plots/feature_importances.png\")\n",
        "    mlflow.log_artifact(\"plots/feature_importances.png\", artifact_path=\"plots\")\n",
        "\n",
        "    with open(\"plots/best_model_params.txt\", \"w\") as f:\n",
        "      for key, value in best_params.items():\n",
        "        f.write(f\"{key}: {value}\\n\")\n",
        "    mlflow.log_artifact(\"plots/best_model_params.txt\", artifact_path=\"plots\")\n",
        "\n",
        "#PUNTO 7 CHECK\n",
        "\n",
        "  return best_model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  optimize_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt\n",
        "#Punto 6 check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025/06/02 01:17:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/06/02 01:17:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
            "2025/06/02 01:17:24 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/06/02 01:17:24 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "\u001b[32m[I 2025-06-02 01:17:24,283]\u001b[0m A new study created in memory with name: no-name-fbd5dea4-bab8-49b7-a8b8-f53e3a736208\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:17:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:17:24] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:17:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:17:38,198]\u001b[0m Trial 0 finished with value: 0.24742268041237114 and parameters: {'max_depth': 4, 'learning_rate': 0.005710890039368646, 'subsample': 0.7505365760094866, 'colsample_bytree': 0.5619032724705111, 'min_child_weight': 4, 'gamma': 0.02321656345226797, 'n_estimators': 136}. Best is trial 0 with value: 0.24742268041237114.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:17:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:17:38] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:17:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:17:48,781]\u001b[0m Trial 1 finished with value: 0.36046511627906974 and parameters: {'max_depth': 5, 'learning_rate': 0.08214467597649433, 'subsample': 0.6262546814712603, 'colsample_bytree': 0.5176782935115365, 'min_child_weight': 7, 'gamma': 0.7761454450940719, 'n_estimators': 64}. Best is trial 1 with value: 0.36046511627906974.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:17:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:17:49] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:17:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:17:58,928]\u001b[0m Trial 2 finished with value: 0.3674698795180723 and parameters: {'max_depth': 6, 'learning_rate': 0.009310880139869825, 'subsample': 0.9449990374807546, 'colsample_bytree': 0.801417819721491, 'min_child_weight': 6, 'gamma': 0.4511527594228312, 'n_estimators': 198}. Best is trial 2 with value: 0.3674698795180723.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:18:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:18:03] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:18:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:18:11,903]\u001b[0m Trial 3 finished with value: 0.3772455089820359 and parameters: {'max_depth': 6, 'learning_rate': 0.0034657706034664183, 'subsample': 0.7137578274216002, 'colsample_bytree': 0.9221577529717541, 'min_child_weight': 1, 'gamma': 0.3142845892142213, 'n_estimators': 293}. Best is trial 3 with value: 0.3772455089820359.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:18:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:18:17] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:18:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:18:25,822]\u001b[0m Trial 4 finished with value: 0.391812865497076 and parameters: {'max_depth': 8, 'learning_rate': 0.0014795570088594297, 'subsample': 0.6424748373325424, 'colsample_bytree': 0.9982385315962639, 'min_child_weight': 4, 'gamma': 0.5317481941781368, 'n_estimators': 200}. Best is trial 4 with value: 0.391812865497076.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:18:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:18:30] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:18:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:18:39,433]\u001b[0m Trial 5 finished with value: 0.40350877192982454 and parameters: {'max_depth': 6, 'learning_rate': 0.008593405463339091, 'subsample': 0.8235103262806205, 'colsample_bytree': 0.8462487732586599, 'min_child_weight': 4, 'gamma': 0.6971121538356041, 'n_estimators': 296}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:18:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:18:40] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:18:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:18:51,015]\u001b[0m Trial 6 finished with value: 0.3669724770642202 and parameters: {'max_depth': 8, 'learning_rate': 0.007899394377842898, 'subsample': 0.7471011526094891, 'colsample_bytree': 0.5896222824526277, 'min_child_weight': 6, 'gamma': 0.10566641421601064, 'n_estimators': 259}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:18:51 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:18:51] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:01,882]\u001b[0m Trial 7 finished with value: 0.3496932515337423 and parameters: {'max_depth': 5, 'learning_rate': 0.011890236286678426, 'subsample': 0.6877567233407669, 'colsample_bytree': 0.8109885349698025, 'min_child_weight': 7, 'gamma': 0.43120407777153613, 'n_estimators': 209}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:19:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:19:02] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:10,766]\u001b[0m Trial 8 finished with value: 0.22758620689655173 and parameters: {'max_depth': 6, 'learning_rate': 0.002491072579125967, 'subsample': 0.6335291758315653, 'colsample_bytree': 0.6559183087559122, 'min_child_weight': 3, 'gamma': 0.5905127045704928, 'n_estimators': 38}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:19:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:19:11] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:21,660]\u001b[0m Trial 9 finished with value: 0.38746438746438744 and parameters: {'max_depth': 7, 'learning_rate': 0.032362057136914826, 'subsample': 0.8943278601015398, 'colsample_bytree': 0.9971097539081459, 'min_child_weight': 3, 'gamma': 0.11218709332555554, 'n_estimators': 65}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:19:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:19:22] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:32,199]\u001b[0m Trial 10 finished with value: 0.27631578947368424 and parameters: {'max_depth': 3, 'learning_rate': 0.023930995944302102, 'subsample': 0.5049125389882153, 'colsample_bytree': 0.7113762970006323, 'min_child_weight': 1, 'gamma': 0.9845282772549684, 'n_estimators': 119}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:19:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:19:34] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:44,012]\u001b[0m Trial 11 finished with value: 0.39420289855072466 and parameters: {'max_depth': 8, 'learning_rate': 0.001182720291573477, 'subsample': 0.8365290829065569, 'colsample_bytree': 0.8937326783516626, 'min_child_weight': 4, 'gamma': 0.6913037049169795, 'n_estimators': 234}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:19:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:19:48] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:19:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:19:56,782]\u001b[0m Trial 12 finished with value: 0.36036036036036034 and parameters: {'max_depth': 7, 'learning_rate': 0.0010697283867387637, 'subsample': 0.8496386901709274, 'colsample_bytree': 0.8824994050343821, 'min_child_weight': 4, 'gamma': 0.7011602351912114, 'n_estimators': 288}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:02] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:20:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:20:10,930]\u001b[0m Trial 13 finished with value: 0.36795252225519287 and parameters: {'max_depth': 7, 'learning_rate': 0.003118568699980514, 'subsample': 0.833691405964277, 'colsample_bytree': 0.8841326918425045, 'min_child_weight': 5, 'gamma': 0.882635701271996, 'n_estimators': 245}. Best is trial 5 with value: 0.40350877192982454.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:13] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:20:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:20:23,171]\u001b[0m Trial 14 finished with value: 0.4068767908309456 and parameters: {'max_depth': 8, 'learning_rate': 0.02469830211220776, 'subsample': 0.9655115719259008, 'colsample_bytree': 0.8034208131900792, 'min_child_weight': 2, 'gamma': 0.7011364076685085, 'n_estimators': 241}. Best is trial 14 with value: 0.4068767908309456.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:23] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:20:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:20:33,752]\u001b[0m Trial 15 finished with value: 0.2857142857142857 and parameters: {'max_depth': 3, 'learning_rate': 0.019555834064844024, 'subsample': 0.9776613654456259, 'colsample_bytree': 0.7630248950626451, 'min_child_weight': 2, 'gamma': 0.7874099934461847, 'n_estimators': 171}. Best is trial 14 with value: 0.4068767908309456.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:34] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:20:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:20:43,324]\u001b[0m Trial 16 finished with value: 0.4132231404958678 and parameters: {'max_depth': 4, 'learning_rate': 0.047312490053357116, 'subsample': 0.9948155449307234, 'colsample_bytree': 0.7091181249432368, 'min_child_weight': 2, 'gamma': 0.31170073374186213, 'n_estimators': 260}. Best is trial 16 with value: 0.4132231404958678.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:46] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:20:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:20:55,157]\u001b[0m Trial 17 finished with value: 0.4251968503937008 and parameters: {'max_depth': 4, 'learning_rate': 0.06474505616333877, 'subsample': 0.934952328342833, 'colsample_bytree': 0.6835255609056782, 'min_child_weight': 2, 'gamma': 0.2700991228316586, 'n_estimators': 256}. Best is trial 17 with value: 0.4251968503937008.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:20:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:20:55] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:05,799]\u001b[0m Trial 18 finished with value: 0.41304347826086957 and parameters: {'max_depth': 4, 'learning_rate': 0.09198716659266826, 'subsample': 0.9992141105761452, 'colsample_bytree': 0.6719936045282823, 'min_child_weight': 2, 'gamma': 0.2928374206124645, 'n_estimators': 170}. Best is trial 17 with value: 0.4251968503937008.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:06 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:06] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:16,317]\u001b[0m Trial 19 finished with value: 0.41899441340782123 and parameters: {'max_depth': 4, 'learning_rate': 0.05100556020404975, 'subsample': 0.9188190262545409, 'colsample_bytree': 0.6316299314519873, 'min_child_weight': 3, 'gamma': 0.27382449135635734, 'n_estimators': 260}. Best is trial 17 with value: 0.4251968503937008.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:17] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:25,951]\u001b[0m Trial 20 finished with value: 0.40804597701149425 and parameters: {'max_depth': 3, 'learning_rate': 0.05407149091624469, 'subsample': 0.8916454705992201, 'colsample_bytree': 0.611683365416395, 'min_child_weight': 3, 'gamma': 0.21388826289169804, 'n_estimators': 216}. Best is trial 17 with value: 0.4251968503937008.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:26] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:36,783]\u001b[0m Trial 21 finished with value: 0.4281842818428184 and parameters: {'max_depth': 4, 'learning_rate': 0.047823074142984826, 'subsample': 0.9256004617588542, 'colsample_bytree': 0.706574583414439, 'min_child_weight': 2, 'gamma': 0.34492961028643626, 'n_estimators': 260}. Best is trial 21 with value: 0.4281842818428184.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:37] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:47,498]\u001b[0m Trial 22 finished with value: 0.44680851063829785 and parameters: {'max_depth': 4, 'learning_rate': 0.058811103298158605, 'subsample': 0.921581512308393, 'colsample_bytree': 0.6403357546499493, 'min_child_weight': 1, 'gamma': 0.21819807107765832, 'n_estimators': 265}. Best is trial 22 with value: 0.44680851063829785.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:48] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:21:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:21:56,970]\u001b[0m Trial 23 finished with value: 0.44041450777202074 and parameters: {'max_depth': 5, 'learning_rate': 0.06469168006121656, 'subsample': 0.883528876864128, 'colsample_bytree': 0.7014023157341854, 'min_child_weight': 1, 'gamma': 0.41025701740717374, 'n_estimators': 277}. Best is trial 22 with value: 0.44680851063829785.\u001b[0m\n",
            "/content/optimize.py:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
            "2025/06/02 01:21:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:21:58] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\"\n",
            "\u001b[31m2025/06/02 01:22:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "\u001b[32m[I 2025-06-02 01:22:08,683]\u001b[0m Trial 24 finished with value: 0.43386243386243384 and parameters: {'max_depth': 5, 'learning_rate': 0.034786375781042086, 'subsample': 0.8723167719341612, 'colsample_bytree': 0.7349980651643208, 'min_child_weight': 1, 'gamma': 0.3897154422555502, 'n_estimators': 277}. Best is trial 22 with value: 0.44680851063829785.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python optimize.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2iG18289j9"
      },
      "source": [
        "# **2. FastAPI (2.0 puntos)**\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
        "</div>\n",
        "\n",
        "Con el modelo ya entrenado, la idea de esta secci√≥n es generar una API REST a la cual se le pueda hacer *requests* para as√≠ interactuar con su modelo. En particular, se le pide:\n",
        "\n",
        "- Guardar el c√≥digo de esta secci√≥n en el archivo `main.py`. Note que ejecutar `python main.py` deber√≠a levantar el servidor en el puerto por defecto.\n",
        "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
        "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medici√≥n de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
        "\n",
        "```json\n",
        "{\n",
        "   \"ph\":10.316400384553162,\n",
        "   \"Hardness\":217.2668424334475,\n",
        "   \"Solids\":10676.508475429378,\n",
        "   \"Chloramines\":3.445514571005745,\n",
        "   \"Sulfate\":397.7549459751925,\n",
        "   \"Conductivity\":492.20647361771086,\n",
        "   \"Organic_carbon\":12.812732207582542,\n",
        "   \"Trihalomethanes\":72.28192021570328,\n",
        "   \"Turbidity\":3.4073494284238364\n",
        "}\n",
        "```\n",
        "\n",
        "Su servidor deber√≠a retornar una respuesta HTML con c√≥digo 200 con:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"potabilidad\": 0 # respuesta puede variar seg√∫n el clasificador que entrenen\n",
        "}\n",
        "```\n",
        "\n",
        "**`HINT:` Recuerde que puede utilizar [http://localhost:8000/docs](http://localhost:8000/docs) para hacer un `POST`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi[all] in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (4.13.2)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all])\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (3.1.6)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[all])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (2.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (6.0.2)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi[all])\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from fastapi[all]) (3.10.18)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (0.34.3)\n",
            "Collecting pydantic-settings>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pydantic-extra-types>=2.0.0 (from fastapi[all])\n",
            "  Downloading pydantic_extra_types-2.10.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[all])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[all]) (3.10)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.15.3)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all])\n",
            "  Downloading rich_toolkit-0.14.7-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[all]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[all]) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.5->fastapi[all]) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[all]) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.0->fastapi[all])\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (8.2.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all])\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"all\"->fastapi[all]) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->fastapi[all]) (1.3.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"all\"->fastapi[all]) (0.1.2)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading pydantic_extra_types-2.10.4-py3-none-any.whl (37 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.7-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, ujson, python-multipart, python-dotenv, httptools, dnspython, watchfiles, email-validator, rich-toolkit, pydantic-settings, pydantic-extra-types, fastapi-cli\n",
            "Successfully installed dnspython-2.7.0 email-validator-2.2.0 fastapi-cli-0.0.7 httptools-0.6.4 pydantic-extra-types-2.10.4 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 rich-toolkit-0.14.7 ujson-5.10.0 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "#!pip install \"fastapi[all]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class parametros(BaseModel): #DEFINICION DE LOS PARAMETROS DEL MODELO, PARA QUE SEAN UTILIZADOS EN EL POST DEL PROGRAMA\n",
        "  ph: float\n",
        "  Hardness: float\n",
        "  Solids: float\n",
        "  Chloramines: float\n",
        "  Sulfate: float\n",
        "  Conductivity: float\n",
        "  Organic_carbon: float\n",
        "  Trihalomethanes: float\n",
        "  Turbidity: float\n",
        "\n",
        "app = FastAPI() #CREACION DE APP\n",
        "\n",
        "\n",
        "try:\n",
        "  with open(\"models/best_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "except FileNotFoundError:\n",
        "  model = None\n",
        "  print(\"El archivo models/best_model.pkl no existe.\")\n",
        "\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def home():\n",
        "  return {\n",
        "      \"Mensaje\": \"Bievenid@s, esta es una API para predicci√≥n de potabilidad del agua\",\n",
        "      \"Descripci√≥n\": \"Esta predicci√≥n usa un modelo XGBoost con optimizaci√≥n de hiperparametros desde optuna, este modelo utiliza distintos parametros del agua\",\n",
        "      \"Input\": {\n",
        "          \"tipo\": \"objecto JSON, base de datos con los siguientes parametros\",\n",
        "          \"parametros\":[\n",
        "              \"ph\",\n",
        "              \"Hardness\",\n",
        "              \"Solids\",\n",
        "              \"Chloramines\",\n",
        "              \"Sulfate\",\n",
        "              \"Conductivity\",\n",
        "              \"Organic_carbon\",\n",
        "              \"Trihalomethanes\",\n",
        "              \"Turbidity\"\n",
        "          ]},\n",
        "      \"Output\": {\n",
        "          \"tipo\": \"Objeto JSON\",\n",
        "          \"parametro\": \"potabilidad\",\n",
        "          \"valores\": \"1 si es potable, 0 si no lo es\"\n",
        "          }}\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/potabilidad\")\n",
        "async def predecir_potabilidad(data: parametros):\n",
        "  if model is None:\n",
        "    return {\"error\": \"El modelo no est√° disponible.\"}\n",
        "  try:\n",
        "    input_data = pd.DataFrame([data.dict()])\n",
        "    prediction_potabilidad = model.predict(input_data)\n",
        "    return {\"potabilidad\": int(prediction_potabilidad[0])}\n",
        "  except Exception as e:\n",
        "    return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000) #se utiliza el puerto default 8000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/main.py\", line 4, in <module>\n",
            "    import pandas as pd\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\", line 49, in <module>\n",
            "    from pandas.core.api import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\", line 28, in <module>\n",
            "    from pandas.core.arrays import Categorical\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
            "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/arrays/arrow/__init__.py\", line 1, in <module>\n",
            "    from pandas.core.arrays.arrow.accessors import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/arrays/arrow/accessors.py\", line 23, in <module>\n",
            "    import pyarrow.compute as pc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/compute.py\", line 336, in <module>\n",
            "    _make_global_functions()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/compute.py\", line 333, in _make_global_functions\n",
            "    g[cpp_name] = g[name] = _wrap_function(name, func)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/compute.py\", line 304, in _wrap_function\n",
            "    return _decorate_compute_function(wrapper, name, func, options_class)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/compute.py\", line 170, in _decorate_compute_function\n",
            "    options_class_doc = _scrape_options_class_doc(options_class)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/compute.py\", line 117, in _scrape_options_class_doc\n",
            "    doc = docscrape.NumpyDocString(options_class.__doc__)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 154, in __init__\n",
            "    self._parse()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 411, in _parse\n",
            "    self[section] = self._parse_param_list(content)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 243, in _parse_param_list\n",
            "    desc = r.read_to_next_unindented_line()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 95, in read_to_next_unindented_line\n",
            "    return self.read_to_condition(is_unindented)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 77, in read_to_condition\n",
            "    if condition_func(line):\n",
            "       ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/vendored/docscrape.py\", line 94, in is_unindented\n",
            "    return (line.strip() and (len(line.lstrip()) == len(line)))\n",
            "            ^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSausqDJ9CQh"
      },
      "source": [
        "# **3. Docker (2 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmC483flS00"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niMA_qsCjqlv"
      },
      "source": [
        "Tras el √©xito de su aplicaci√≥n web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
        "\n",
        "## **3.1 Creaci√≥n de Container (1 punto)**\n",
        "\n",
        "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el c√≥digo fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicaci√≥n. Para la dockerizaci√≥n, aseg√∫rese de cumplir con los siguientes puntos:\n",
        "\n",
        "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
        "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
        "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
        "4. **Incluir im√°genes en el notebook** que muestren la ejecuci√≥n del contenedor y los resultados obtenidos.\n",
        "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en t√©rminos de recursos.\n",
        "\n",
        "## **3.2 Preguntas de Smapina (1 punto)**\n",
        "Tras haber experimentado con Docker, Smapina desea profundizar m√°s en el tema y decide realizarle las siguientes consultas:\n",
        "\n",
        "- ¬øC√≥mo se diferencia Docker de una m√°quina virtual (VM)?\n",
        "- ¬øCu√°l es la diferencia entre usar Docker y ejecutar la aplicaci√≥n directamente en el sistema local?\n",
        "- ¬øC√≥mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci√≥n?\n",
        "- ¬øC√≥mo se gestionan los vol√∫menes en Docker para la persistencia de datos?\n",
        "- ¬øQu√© son Dockerfile y docker-compose.yml, y cu√°l es su prop√≥sito?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ¬øC√≥mo se diferencia Docker de una m√°quina virtual (VM)?\n",
        "\n",
        "Docker es un software que por medio de los *contenedores* permite crear y ejecutar aplicaciones, con todas las dependencias y configuraciones necesarias para trabajar (como por ejemplo, especificaciones de otro sistema operativo), sin tener que generar particiones en el Hardware, como s√≠ lo hace una VM. En palabras sencillas y de forma bastante hol√≠stica, Docker permite \"usar\" otros sistemas operativos de manera liviana y de r√°pida migraci√≥n, mientras que una VM requiere instalar el sistema operativo completo en una nueva partici√≥n (lo cual es muy pesado) para poder operar.\n",
        "\n",
        "> ¬øCu√°l es la diferencia entre usar Docker y ejecutar la aplicaci√≥n directamente en el sistema local?\n",
        "\n",
        "Al usar Docker, la aplicaci√≥n se ejecuta dentro de un contenedor con todas las especificaciones y dependencias compatibles para su funcionamiento y es replicable para cualquier equipo que tenga instalado Docker. En cambio, al ejecutar la aplicaci√≥n directamente en el sistema local, si la aplicaci√≥n fue creada en la misma m√°quina probablemente funcione pero puede fallar en otra que no tenga las mismas especificaciones: el cl√°sico \"pero en mi m√°quina funcionaba\". A√∫n peor, si la aplicaci√≥n no fue creada en la misma m√°quina que la que se est√° ejecutando, pueden presentarse dificultades de compatibilidad y conflictos de dependencias que obligan a instalar manualmente todas las dependencias requeridas para el funcionamiento de la aplicaci√≥n... o bien instalar Docker.\n",
        "\n",
        "> ¬øC√≥mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci√≥n?\n",
        "\n",
        "Por medio de la creaci√≥n de *im√°genes* y el uso de *contenedores*. Lo primero hace referencia a la creaci√≥n del `Dockerfile` con todas las especificaciones base y las dependencias necesarias para el funcionamiento de la(s) aplicaci√≥n(es) a ejecutar (sistema operativo, librer√≠as, etc.) y lo segundo hace referencia a un cierto tipo de \"entorno\" en donde esta imagen es ejecutada y por lo tanto, las aplicaciones almacenadas en este contenedor funcionan bajo las especificaciones de dicha imagen. Con ello, se pueden tener diferentes contenedores que pueden interactuar entre s√≠ y tener cada uno sus especificaciones para que los entornos de desarrollo y producci√≥n funcionen sin presentar discrepancias ni problemas en su ejecuci√≥n.\n",
        "\n",
        "> ¬øC√≥mo se gestionan los vol√∫menes en Docker para la persistencia de datos?\n",
        "\n",
        "Los vol√∫menes se gestionan de manera independiente a los contenedores y permiten almacenar informaci√≥n importante que de otro modo se perder√≠a en un contenedor luego de ser reiniciado o eliminado. En ese sentido, funcionan como una memoria cach√© dentro de Docker para almacenar informaci√≥n relevante cada vez que se solicite. Existen comandos para crear vol√∫menes y guardarlos en directorios espec√≠ficos al momento de ejecutar un contenedor.\n",
        "\n",
        "> ¬øQu√© son Dockerfile y docker-compose.yml, y cu√°l es su prop√≥sito?\n",
        "\n",
        "* Dockerfile: Es un archivo de texto que contiene \"instrucciones\" para construir una imagen de Docker. Es decir, define las especificaciones del entorno de la aplicaci√≥n a ejecutar: qu√© sistema base usar, qu√© dependencias instalar, c√≥mo copiar archivos, qu√© comandos ejecutar, etc.\n",
        "\n",
        "* docker-compose.yml: Es un archivo que permite definir y gestionar m√∫ltiples contenedores y sus relaciones (por ejemplo, una app, una base de datos, un cache). Define c√≥mo se deben ejecutar los contenedores, sus variables de entorno, vol√∫menes, redes, dependencias, etc. Es muy √∫til cuando se tiene una aplicaci√≥n (o varias) con muchas utilidades y servicios diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xJ_ZK1IfnZW"
      },
      "source": [
        "# Conclusi√≥n\n",
        "\n",
        "√âxito!\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://i.pinimg.com/originals/55/f5/fd/55f5fdc9455989f8caf7fca7f93bd96a.gif\" width=\"500\">\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
