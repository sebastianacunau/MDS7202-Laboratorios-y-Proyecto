{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 4: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Oto√±o 2025</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Sebasti√°n Acu√±a U.\n",
        "- Nombre de alumno 2: Mart√≠n Guzm√°n S.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio](https://github.com/sebastianacunau/MDS7202-Laboratorios-y-Proyecto.git)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/23/b7/6e/23b76e9e77e63c0eec1a7b28372369e3.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset\n",
        "\n",
        "data_sets = create_data(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "def plot_scatter(n_samples=5000):\n",
        "    # Se generan los datasets con el n√∫mero de muestras indicado\n",
        "    data_sets = create_data(n_samples)\n",
        "\n",
        "    # Se listan los modelos\n",
        "    modelos = ['KMeans', 'DBSCAN', 'Ward', 'GMM']\n",
        "\n",
        "    # Se crea la grilla de subgr√°ficos\n",
        "    fig = make_subplots(rows=3, cols=4, column_titles=['k-means', 'DBSCAN', 'Ward', 'GMM'], \n",
        "                        row_titles=['Moons', 'Blobs', 'Mutated'],\n",
        "                        x_title='Models', y_title='Datasets')\n",
        "    \n",
        "    # Se agregan los subgr√°ficos\n",
        "    for i, (nombre, dataset) in enumerate(data_sets.items()):\n",
        "        x = dataset['x']\n",
        "        y = dataset['classes']\n",
        "        n_cluster = dataset['n_cluster']\n",
        "\n",
        "        for j, modelo in enumerate(modelos):\n",
        "            if modelo == 'Ward':\n",
        "                model = AgglomerativeClustering(n_clusters=n_cluster)\n",
        "            elif modelo == 'GMM':\n",
        "                model = GaussianMixture(n_components=n_cluster)\n",
        "            elif modelo == 'DBSCAN':\n",
        "                model = DBSCAN(eps=0.2, min_samples=5)\n",
        "            else:\n",
        "                model = KMeans(n_clusters=n_cluster)\n",
        "\n",
        "            # Se inicia el contador de tiempo\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Se ajusta el modelo\n",
        "            if modelo == 'GMM':\n",
        "                model.fit(x)\n",
        "                labels = model.predict(x)\n",
        "            else:\n",
        "                labels = model.fit_predict(x)\n",
        "\n",
        "            # Se detiene el contador de tiempo\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "\n",
        "            # Se calcula la m√©trica Silhouette\n",
        "            if modelo == 'GMM':\n",
        "                silhouette = silhouette_score(x, labels)\n",
        "            else:\n",
        "                silhouette = silhouette_score(x, labels)\n",
        "\n",
        "            # Se agrega el gr√°fico\n",
        "            fig.add_trace(go.Scatter(x=x[:, 0], y=x[:, 1], mode='markers', \n",
        "                                    marker=dict(color=labels, colorscale=\"Viridis\", size=5, showscale=False),\n",
        "                                    showlegend=False), row=i+1, col=j+1)\n",
        "            \n",
        "            # Se agrega el tiempo de ejecuci√≥n y la m√©trica Silhouette como t√≠tulo del subgr√°fico\n",
        "            fig.add_annotation(text=f\"{elapsed_time:.2f} [s] | s: {silhouette:.2f}\",\n",
        "                               xref=\"x domain\", yref=\"y domain\", x=1, y=1, showarrow=False,\n",
        "                               font=dict(size=10), row=i+1, col=j+1, align='center')\n",
        "        \n",
        "    fig.update_layout(height=800, width=1200, title_text=\"Comparaci√≥n de tiempos de ejecuci√≥n por t√©cnica\")\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se ejecuta la funci√≥n para graficar una muestra de 1000 puntos\n",
        "plot_scatter(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se ejecuta la funci√≥n para graficar una muestra de 5000 puntos\n",
        "plot_scatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se ejecuta la funci√≥n para graficar una muestra de 10000 puntos\n",
        "plot_scatter(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_lucer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "# Carga de datos\n",
        "airline_df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "airline_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se seleccionan s√≥lo las variables num√©ricas\n",
        "airline_num_df = airline_df.select_dtypes(include=['int', 'float']).drop(columns=['id'])\n",
        "airline_num_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "airline_num_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in airline_num_df:\n",
        "    fig = px.histogram(airline_num_df, x=col, marginal=\"box\", title = 'Histogram of ' + col)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "airline_num_df.corr().style.background_gradient(cmap='coolwarm', axis=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**An√°lisis y desarrollo de respuestas:**\n",
        "\n",
        "1. Usar variables categ√≥ricas en el contexto de algoritmos de clustering podr√≠a no ser una buena idea, pues estos realizan clasificaciones principalmente a trav√©s del c√°lculo de distancias y definiendo criterios para determinar si un par de puntos se encuentran \"cerca\" o \"lejos\". \n",
        "\n",
        "    En ese sentido, insertar variables categ√≥ricas puede afectar negativamente esta clase de modelos si no se analizan lo suficiente, pues en general una categorizaci√≥n no entrega un orden o jerarqu√≠a entre categor√≠as que sea parametrizable num√©ricamente y as√≠ puedan ser compatibles con los modelos.\n",
        "\n",
        "2. De las variables que representan niveles de satisfacci√≥n (escala de 0-5), se puede observar que, a pesar de ser variables discretas, tienen distribuciones similares a una distribuci√≥n beta-binomial o en algunos casos normal. En el sentido de medidas de tendencia central, las medias superan levemente la calificaci√≥n de 3 estrellas y la mayor parte de las medianas y modas se encuentran entre 3 y 4 estrellas. Sobre la edad, se observa que la mayor parte de los datos corresponde a gente entre los 20 y 60 a√±os de edad, con modas en 39 y 25 a√±os. Su distribuci√≥n podr√≠a considerarse suficientemente normal con media cercana a 40. El histograma de distancia de viaje muestra que la mayoria de los viajes tienen distancias menores a 1000 km, pero hay data significativa de viajes hasta aproximadamente los 4000 km de distancia. Distancias mayores son pr√°cticamente outliers en la data. Sobre el tiempo de retraso en los vuelos, se observa que la mayor√≠a de los vuelos no presenta retrasos y m√°s del 75% de los vuelos presenta retrasos menores a 13 min. En ese sentido la data se comporta similar a una exponencial con un par√°metro $\\lambda$ elevado. Sin embargo, hay tambi√©n tiempos de retraso muy elevados, que hay que tratar como outliers en la data.\n",
        "\n",
        "3. Si el objetivo es realizar *clustering* con algunas de estas variables, puede ser muy recomendable realizar un escalamiento de los datos previamente, como por ejemplo una estandarizaci√≥n, pues si bien hay varias columnas cuyo rango va de 0 a 5 (la cantidad de estrellas correspondientes al nivel de satisfacci√≥n de los clientes), tambi√©n hay otras tantas que operan en escalas completamente distintas, como por ejemplo los tiempos de retraso, el tiempo de viaje o la edad de los pasajeros. Si estos datos no son escalados, entonces los modelos de clustering, que como se mencion√≥ anteriormente se basan fundamentalmente en c√°lculos de distancia entre puntos, no funcionar√°n correctamente pues ignorar√°n los cambios en variables cuyo rango es peque√±o en desmedro de otros cuyo dominio es demasiado grande.\n",
        "\n",
        "4. De la matriz de correlaci√≥n podemos observar que hay variables fuertemente correlacionadas, algunas muy marcadas como los minutos de atraso en la salida y los de la llegada, cuya correlaci√≥n e incluso causalidad es evidente, pues un atraso en el horario de salida implica muy probablemente un atraso en la llegada. Tambi√©n hay otros pares o grupos de correlaciones bastante fuertes (sobre 0.5), que se detallan a continuaci√≥n:\n",
        "    * Cleanliness, Food and drink, Seat comfort, Inflight entertainment: es razonable pensar que la satisfacci√≥n dentro del avi√≥n viene acompa√±ado de asientos c√≥modos, limpios, buena alimentaci√≥n y entretenimiento.\n",
        "    * Inflight service, On-board service, Baggage handling: estas correlaciones pueden indicar que el servicio prestado por el personal de la aerol√≠nea es uniforme a trav√©s de sus diferentes servicios, en el sentido que la gente suele calificar estos 3 servicios de manera similar.\n",
        "    * Ease of online booking, Inflight wifi service: esta es probablemente la correlaci√≥n m√°s llamativa y dif√≠cil de explicar. Est√° indicando que la facilidad para realizar reservaciones en l√≠nea de esta aerol√≠nea est√° fuertemente correlacionada con la calidad de internet de sus aviones. ¬øSer√° gente que valora mucho el uso de internet en general o ser√° que la gente suele hacer uso del wifi en los aviones para hacer m√°s reservaciones de vuelo?\n",
        "\n",
        "5. En vista de los resultados observados en la matriz de correlaci√≥n y como nuestra intenci√≥n es comprender el nivel de satisfacci√≥n de los pasajeros, podemos primeramente seleccionar s√≥lo una variable por grupo de variables fuertemente correlacionadas pues probablemente expliquen al resto y adem√°s concentran temas que entre s√≠ no se encuentran necesariamente relacionados pero cubren varios aspectos del servicio de la aerol√≠nea. \n",
        "\n",
        "    En ese sentido se seleccionar√°n los atributos **SEAT COMFORT, INFLIGHT SERVICE, EASE OF ONLINE BOOKING**, que buscan mostrar el nivel de satisfacci√≥n con el avi√≥n mismo, el servicio del personal y el proceso previo de reserva de boletos. Estos atributos fueron seleccionados por sobre sus similares en correlaci√≥n pues suelen ser m√°s generales y en las distribuciones se ve que son los que presentan la menor cantidad de ceros, indicando que en general siempre est√°n presentes y por lo tanto aplica evaluarlos.\n",
        "    \n",
        "    Como cuarto atributo se seleccionar√° la edad (**AGE**), para intentar ver qu√© aspectos son m√°s valorados dependiendo del rango etario de los pasajeros. Notar que la selecci√≥n de este atributo obligar√° realizar escalamiento sobre los datos pues su rango es diferente a los dem√°s.\n",
        "    \n",
        "    Entre las variables que podr√≠an considerarse pero ser√°n descartadas est√°n los tiempos de retraso, pues se vio de la distribuci√≥n que la inmensa mayor√≠a de los vuelos apenas presenta tiempos de retraso, por lo que a priori ser√° dif√≠cil establecer relaciones y adem√°s al escalar estos datos la mayor√≠a quedar√° en cero, siendo de poca ayuda pr√°ctica. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reducido = airline_num_df[['Age', 'Seat comfort', 'Inflight service', 'Ease of Online booking']]\n",
        "df_reducido.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://media4.giphy.com/media/vWst8QUOKAot6MHEZe/giphy.gif?cid=6c09b952gm5xylrj4k5caq2slgwivx9azbgb0ox297sk5zjx&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=g\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler()), # Se escalan los datos\n",
        "    ('pca', PCA(n_components=2)) # Se reduce la dimensionalidad\n",
        "])\n",
        "\n",
        "# Se aplica el pipeline a los datos\n",
        "transformed_data = pipeline.fit_transform(df_reducido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se crea un scatter plot de la data transformada\n",
        "fig = px.scatter(\n",
        "    x=transformed_data[:, 0], \n",
        "    y=transformed_data[:, 1], \n",
        "    title=\"Scatter Plot en 2D del PCA\",\n",
        "    labels={'x': 'Componente principal 1', 'y': 'Componente principal 2'}\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "be86896911244aa89e3b5f3f00a286af",
        "deepnote_cell_type": "code",
        "id": "iaPZFmjyrqDA"
      },
      "outputs": [],
      "source": [
        "# Se crea un pipeline donde se aplique Isolation Forest\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler()), # Se escalan los datos\n",
        "    ('iso_forest', IsolationForest(contamination=0.1)) # Se aplica Isolation Forest\n",
        "])\n",
        "\n",
        "# Se aplica el pipeline a los datos\n",
        "pipeline.fit(df_reducido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se obtiene el resultado de la predicci√≥n\n",
        "outliers = pipeline.predict(df_reducido)\n",
        "\n",
        "# Se crea un scatter plot de la data transformada\n",
        "fig = px.scatter(\n",
        "    x=transformed_data[:, 0],\n",
        "    y=transformed_data[:, 1],\n",
        "    color=outliers,  # Color points by outlier status\n",
        "    title='Detecci√≥n de Anomal√≠as con Isolation Forest',\n",
        "    labels={'x': 'Componente Principal 1', 'y': 'Componente Principal 2', 'color': 'Outlier'}\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**An√°lisis de resultados:** Si consideramos que en este gr√°fico existen 6 clusters, se observa que buena parte de las anomal√≠as ocurren en los clusters de los extremos y adem√°s la mayor parte de los outliers se encuentran en las fronteras de los mismos, lo que parece estar indicando un funcionamiento suficiente del modelo Isolation Forest para la detecci√≥n de anomal√≠as. De todas formas, puede que el modelo entregue resultados con mejor separaci√≥n si se realiza un PCA en 3 dimensiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:** El criterio adecuado para seleccionar el n√∫mero optimo de cluster es el criterio del codo, al ver gr√°ficamente los resultados de las metricas AIC y BIC, observamos una disminuci√≥n en estas m√©tricas en 4 clusters.\n",
        "\n",
        "La raz√≥n te√≥rica detras de este criterio, es debido que el AIC (Akaike Information Criterion) que mide la calidad relativa de un modelo estad√≠stico para un conjunto de datos determinado y BIC (Bayesian Information Criterion) funcionan de manera parecida, pero este √∫ltimo es m√°s estricto en la penalizaci√≥n por complejidad.\n",
        "\n",
        "B√°sicamente, estos criterios penalizan la complejidad de los modelos previniendo el overfitting. Al encontrar el menor score posible en estas m√©tricas, tomamos un modelo menos complejo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "GMM_pipeline = Pipeline([\n",
        "    ('Scaler', MinMaxScaler()),\n",
        "    ('GMM', GaussianMixture(random_state=42))\n",
        "])\n",
        "\n",
        "n_clusters= list(range(3, 9))\n",
        "Aic = []\n",
        "Bic = []\n",
        "\n",
        "for n in n_clusters:\n",
        "    GMM_pipeline.set_params(GMM__n_components=n)\n",
        "    GMM_pipeline.fit(df_reducido)\n",
        "\n",
        "    Aic.append(GMM_pipeline['GMM'].aic(df_reducido))\n",
        "    Bic.append(GMM_pipeline['GMM'].bic(df_reducido))\n",
        "\n",
        "resultados_df = pd.DataFrame({'n_clusters': n_clusters, 'AIC': Aic, 'BIC': Bic})\n",
        "resultados_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(resultados_df['n_clusters'], resultados_df['AIC'], label='AIC')\n",
        "plt.plot(resultados_df['n_clusters'], resultados_df['BIC'], label='BIC')\n",
        "plt.xlabel('N√∫mero de cl√∫sters')\n",
        "plt.ylabel('Scores AIC y BIC')\n",
        "plt.title('Comparaci√≥n de m√©tricas de ajuste')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://www.icegif.com/wp-content/uploads/2021/12/icegif-1407.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:** \n",
        "\n",
        "2. En el caso de la proyeccion en 2 dimensiones, no es clara una frontera visual que distinga los diferentes clusters generados, ya que se sobreponen en dos dimensiones.\n",
        "\n",
        "3. La descripci√≥n de los clusters de manera estad√≠stica se encuentra en el c√≥digo de descripci√≥n m√°s abajo, el cual caracteriza la media y la desviaci√≥n est√°ndar de las variables utilizadas. Por ejemplo, el cluster 0, contiene una media de edad de 40 a√±os, con una desviaci√≥n est√°ndar de 14 lo que nos permite ver lo grande que es este cluster.\n",
        "\n",
        "5. Podemos ver una separaci√≥n m√°s clara en la proyecci√≥n en 3 dimensiones, ya que as√≠ eliminamos el factor de sobreposici√≥n de las variables y as√≠ podemos identificar fronteras visuales en los clusters de mejor manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "GMM_pipeline.set_params(GMM__n_components=5)\n",
        "GMM_pipeline.fit(df_reducido)\n",
        "\n",
        "clusters = GMM_pipeline.predict(df_reducido)\n",
        "\n",
        "fig = px.scatter(x = transformed_data[:, 0], y = transformed_data[:, 1], color = clusters,\n",
        "                 title = 'Clusters en 2D',\n",
        "                 labels = {'x': 'Componente Principal 1', 'y': 'Componente Principal 2', 'color': 'Cluster'}\n",
        "                 )\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_stats = df_reducido.groupby(clusters).agg(['mean', 'std'])\n",
        "cluster_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = PCA(n_components=3)\n",
        "transformed_data3 = pca.fit_transform(df_reducido)\n",
        "\n",
        "fig = px.scatter_3d(x = transformed_data3[:, 0], y = transformed_data3[:, 1], z = transformed_data3[:,2] ,color = clusters,\n",
        "                 title = 'Clusters en 3D',\n",
        "                 labels = {'x': 'Componente Principal 1', 'y': 'Componente Principal 2', 'z': 'Componente Principal 3', 'color': 'Cluster'}\n",
        "                 )\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mucho √©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
