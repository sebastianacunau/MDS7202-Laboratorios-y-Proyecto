{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "516acf1d6e9d4ddb9a8acdeb6b1cca14",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "-MGJGjPDimJI"
      },
      "source": [
        "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "befdb70375f04ab79952117eb63723e7",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "SN4W-_BNimJJ"
      },
      "source": [
        "**MDS7202: Laboratorio de ProgramaciÃ³n CientÃ­fica para Ciencia de Datos**\n",
        "\n",
        "### ğŸ‘¨â€ğŸ«ğŸ‘©â€ğŸ« Cuerpo Docente:\n",
        "\n",
        "- Profesor: SebastiÃ¡n Tinoco, Stefano Schiappacasse\n",
        "- Auxiliar: Melanie PeÃ±a Torres, Valentina Rojas Osorio\n",
        "- Ayudante: Valentina ZuÃ±iga, Ãngelo MuÃ±oz\n",
        "\n",
        "### ğŸ‘¨â€ğŸ’»ğŸ‘©â€ğŸ’» Estudiantes:\n",
        "- Estudiante nÂ°1:\n",
        "- Estudiante nÂ°2:\n",
        "\n",
        "_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GjshSnpjGcr"
      },
      "source": [
        "### **Instrucciones importantes**\n",
        "\n",
        "1. **Formato del informe**:  \n",
        "   - El informe debe estar integrado dentro de un **Jupyter Notebook**. No es necesario subirlo a una plataforma externa, pero debe cumplir con los siguientes requisitos:  \n",
        "     - Estructura clara y ordenada.  \n",
        "     - CÃ³digo acompaÃ±ado de explicaciones detalladas.  \n",
        "     - Resultados presentados de forma visual y analÃ­tica.  \n",
        "\n",
        "2. **Descuento por informes deficientes**:  \n",
        "   - Cualquier secciÃ³n del informe que no tenga una explicaciÃ³n adecuada o no respete el formato serÃ¡ penalizada con un descuento en la nota. Esto incluye cÃ³digo sin comentarios o anÃ¡lisis que no sean coherentes con los resultados presentados.\n",
        "   - **Comentarios sin formatear de ChatGPT o herramientas similares serÃ¡n penalizados (e.g: \"Inserta tu modelo acÃ¡\", etc.)**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.giphy.com/media/ZkIUY6LZJMwrSMQMWu/giphy.gif?cid=6c09b952msc755426bpsadn4sysofcpqczczi7x1pghd41sw&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=v\" width=\"400\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "73dd6ad576224431b010e7650d06156e",
        "deepnote_app_block_visible": true,
        "deepnote_cell_type": "markdown",
        "id": "mMwIvE7AimJK"
      },
      "source": [
        "# ğŸ“¬ Entrega Parcial 3 (30% del Proyecto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbrEry-nnsfs"
      },
      "source": [
        "### ğŸ“ª Fecha de Entrega: \n",
        "\n",
        "Esta entrega cuenta con 2 partes:\n",
        "\n",
        "- **Predicciones**: 1 de Julio, 2 de Julio, 3 de Julio, 4 de Julio\n",
        "- **Informe:** 9 de Julio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S9iswjPnxmu"
      },
      "source": [
        "## ğŸ“– Enunciado\n",
        "\n",
        "DespuÃ©s de haber superado con Ã©xito la implementaciÃ³n de sus flujos de trabajo con `Airflow`, el equipo **Deep Drinkers ğŸ¤–** ha demostrado que no solo sabe construir modelos, sino tambiÃ©n integrarlos en pipelines reales listos para producciÃ³n.\n",
        "\n",
        "El equipo tÃ©cnico de **SodAI Drinks ğŸ¥¤** ha quedado tan satisfecho con la automatizaciÃ³n de sus procesos que ahora les ha encomendado una nueva, y final, misiÃ³n:  \n",
        "- ğŸ“Š **Evaluar la calidad real de sus modelos en un entorno mÃ¡s desafiante** \n",
        "- ğŸ§  **Comunicar los hallazgos de forma clara y profesional frente a una comisiÃ³n**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/btbUGSHh3f6eBjbDfh.webp\" width=\"350\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Œ Predicciones\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NTMxntb8rMzmbd1x97.webp\" width=\"500\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "Su *pipeline* automatizado debe demostrar que puede manejar datos reales en producciÃ³n. **SodAI Drinks** ğŸ¥¤ liberarÃ¡ *batches* de datos en fechas diferentes para evaluar si su sistema se adapta correctamente, los cuales simularÃ¡n la llegada de informaciÃ³n nueva (cada batch es una semana).\n",
        "\n",
        "Lo que debe funcionar automÃ¡ticamente:\n",
        "- **EjecuciÃ³n Automatizada**: Su DAG de `Airflow` debe ser capaz de procesar cada *batch* de datos de manera automÃ¡tica cuando estÃ© disponible.\n",
        "- **Monitoreo Continuo**: El *pipeline* debe evaluar la calidad de los datos entrantes y detectar posibles desviaciones respecto al conjunto original.\n",
        "- **DecisiÃ³n de Reentrenamiento**: BasÃ¡ndose en los anÃ¡lisis de *data drift* y mÃ©tricas de rendimiento, el sistema debe determinar automÃ¡ticamente si es necesario reentrenar el modelo.\n",
        "- **Tracking Completo**: Todas las ejecuciones, mÃ©tricas y decisiones deben quedar registradas en `MLFlow` para posterior anÃ¡lisis.\n",
        "- **GeneraciÃ³n de Predicciones**: Para cada *batch* procesado, el sistema debe generar las predicciones correspondientes y almacenarlas de manera organizada.\n",
        "\n",
        "**IMPORTANTE: Es imperativo que guarden los resultados de su pipeline (mÃ©tricas, tracking, predicciones, etc) para su anÃ¡lisis en la siguiente secciÃ³n.**\n",
        "\n",
        "### ğŸ“ŒEntregable: Competencia en CodaLab\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.giphy.com/NomCzPIGoXs3EIq77v.webp\" width=\"300\" height=\"300\">\n",
        "</center>\n",
        "\n",
        "Como parte de esta entrega final, el equipo debe utilizar su pipeline entrenado para **generar predicciones en los nuevos conjuntos de datos mencionados anteriormente**.\n",
        "\n",
        "Estas predicciones deben:\n",
        "\n",
        "- Ser generadas directamente desde el *pipeline* previamente desarrollado.  \n",
        "- Guardarse en archivos `.csv` siguiendo el formato requerido.  \n",
        "- Subirse a la plataforma **CodaLab**, donde se realizarÃ¡ la evaluaciÃ³n final.\n",
        "\n",
        "En CodaLab podrÃ¡n:\n",
        "\n",
        "- Ver el rendimiento de su modelo frente a los de otros equipos.  \n",
        "- Obtener una puntuaciÃ³n basada en la mÃ©trica definida del proyecto.  \n",
        "\n",
        "Cada set de predicciones debe ser publicado en CodaLab en las siguientes fechas:\n",
        "- **Predicciones 1 ğŸ“…** : 1 de Julio (Fecha de predicciÃ³n: 01/01/25 - 05/01/25)\n",
        "    - Note que para este set de predicciones, sÃ³lo tendrÃ¡n acceso a los datos publicados en la Entrega 1.\n",
        "- **Predicciones 2 ğŸ“…** : 2 de Julio (Fecha de predicciÃ³n: 06/01/25 - 12/01/25)\n",
        "- **Predicciones 3 ğŸ“…** : 3 de Julio (Fecha de predicciÃ³n: 13/01/25 - 19/01/25)\n",
        "- **Predicciones 4 ğŸ“…** : 4 de Julio (Fecha de predicciÃ³n: 20/01/25 - 26/01/25)\n",
        "\n",
        "Para simular la llegada de nuevos datos, se publicarÃ¡n los siguientes conjuntos de datos:\n",
        "- **Batch 1 ğŸ“…** : 2 de Julio (Con datos realizados del perÃ­odo 01/01/25 - 05/01/25)\n",
        "- **Batch 2 ğŸ“…** : 3 de Julio (Con datos realizados del perÃ­odo 06/01/25 - 12/01/25)\n",
        "- **Batch 3 ğŸ“…** : 4 de Julio (Con datos realizados del perÃ­odo 13/01/25 - 19/01/25)\n",
        "- **Batch 4 ğŸ“…** 5 de Julio (Con datos realizados del perÃ­odo 20/01/25 - 26/01/25)\n",
        "    - Note como este conjunto de datos se publica **despuÃ©s** de la competencia, por lo que sÃ³lo les servirÃ¡ para la Ãºltima evaluaciÃ³n requerida en el informe.\n",
        "\n",
        "**IMPORTANTE:** Subir los resultados a tiempo en las tres fechas es **<u>OBLIGATORIO</u>** para la evaluaciÃ³n del desempeÃ±o final del equipo. **Por cada fecha en la que no se suban predicciones, se aplicarÃ¡ un descuento de 0.75 puntos (75 dÃ©cimas) sobre la nota de la Entrega 3.**\n",
        "\n",
        "### ğŸ Bonus [0.5 puntos]\n",
        "\n",
        "Como incentivo adicional, se premiarÃ¡ a los **3 equipos con mejor performance en la mÃ©trica F1** con **0.5 puntos de puntaje adicional** sobre la nota de la Entrega 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Œ Informe: Performance del modelo [6.0 puntos]\n",
        "\n",
        "En esta secciÃ³n se espera que el equipo analice de manera retrospectiva el performance de su modelo y saque conclusiones en funciÃ³n de sus resultados. \n",
        "\n",
        "Para esto, tendrÃ¡n que incurrir en 3 tipos de anÃ¡lisis:\n",
        "\n",
        "- **Individual:** Deben evaluar el performance de su modelo tomando cada semana de forma aislada.\n",
        "\n",
        "- **Comparativo:** Deben evaluar el performance de su modelo *a travÃ©s* de las semanas, comparando el desempeÃ±o entre las semanas e identificando posibles tendencias.\n",
        "    - Para esta parte se espera que generen grÃ¡ficos de tendencia y tablas comparativas para apoyar su anÃ¡lisis.\n",
        "\n",
        "- **Conclusiones y Aprendizajes:** Deben escribir sus principales conclusiones y aprendizajes de este proyecto. \n",
        "\n",
        "A lo largo de esta secciÃ³n, se espera que respondan preguntas como:\n",
        "\n",
        "1. Â¿CÃ³mo variaron sus mÃ©tricas a lo largo de los distintos conjuntos de datos? \n",
        "2. Â¿En quÃ© momento el modelo tuvo su peor desempeÃ±o y por quÃ©?\n",
        "3. Â¿Detectaron algÃºn cambio significativo (drift) en la distribuciÃ³n de los datos? Â¿CÃ³mo lo identificaron?  \n",
        "4. Â¿Tuvieron que reentrenar su modelo con los nuevos datos? Â¿PorquÃ©? Â¿AyudÃ³ esto al performance de su modelo?\n",
        "4. Â¿QuÃ© decisiÃ³n tÃ©cnica (modelo, mÃ©trica, imputaciÃ³n, etc.) tuvo mÃ¡s impacto en los resultados?  \n",
        "5. Â¿QuÃ© hiperparÃ¡metro fue el mÃ¡s importante para su modelo? \n",
        "5. Â¿QuÃ© variable fue mÃ¡s influyente en las predicciones? Â¿CÃ³mo lo interpretan? Â¿CÃ³mo cambiÃ³ su importancia con respecto a las otras variables a lo largo de los batch de datos?\n",
        "6. Â¿QuÃ© aprendieron sobre el negocio a partir de los resultados del modelo?\n",
        "7. Â¿QuÃ© limitaciones detectaron en su modelo o en los datos?  \n",
        "\n",
        "**IMPORTANTE: Se espera que en sus respuestas hagan referencia a los artefactos (mÃ©tricas, hiperparÃ¡metros, grÃ¡ficos de interpretabilidad, etc) que su pipeline genera.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media1.tenor.com/m/jyQ3SPT1htEAAAAd/i-love-this-performance-even-more-simon-cowell.gif\" width=\"300\" height=\"300\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ AnÃ¡lisis individual [3.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 1 (01/01/25 - 05/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocesamiento_datos(dataset, semana):\n",
        "    \n",
        "    warnings.filterwarnings('ignore', category=SyntaxWarning)\n",
        "    data_clientes = pd.read_parquet('data/clientes.parquet')\n",
        "    data_productos = pd.read_parquet('data/productos.parquet')\n",
        "    data_transacciones = pd.read_parquet(dataset)\n",
        "\n",
        "    data_transacciones['purchase_date'] = pd.to_datetime(data_transacciones['purchase_date'])\n",
        "    data_transacciones['aÃ±o'] = data_transacciones['purchase_date'].dt.year\n",
        "\n",
        "#se votan duplicados\n",
        "    data_clientes = data_clientes.drop_duplicates()\n",
        "    data_productos = data_productos.drop_duplicates()\n",
        "    data_transacciones = data_transacciones.drop_duplicates()\n",
        "\n",
        "#se eliminan estas columnas ya que solo hay un solo valor, entonces, no es necesario agregarlo al dataset final.\n",
        "    data_clientes = data_clientes.drop(columns = ['num_visit_per_week','region_id', 'zone_id'] )\n",
        "\n",
        "#se unen los dataset\n",
        "    df = data_transacciones.merge(data_clientes, on='customer_id', how='left')\n",
        "    df = df.merge(data_productos, on='product_id', how='left')\n",
        "    df['semana'] = df['purchase_date'].dt.isocalendar().week\n",
        "\n",
        "    df_agrupado = df.groupby(['customer_id', 'product_id', 'semana', 'aÃ±o'])['order_id'].count().reset_index()\n",
        "    df_agrupado.rename(columns={'order_id': 'cantidad_order'}, inplace=True)\n",
        "\n",
        "# se crea el dataset para crear las combinaciones posibles\n",
        "    customer_unicos = df['customer_id'].unique()\n",
        "    productos_unicos = df['product_id'].unique()\n",
        "    semanas_unicas = df['semana'].unique()\n",
        "    aÃ±o_unicos = df['aÃ±o'].unique()\n",
        "\n",
        "    customer_unicos_df = pd.DataFrame({'customer_id': customer_unicos})\n",
        "    productos_unicos_df = pd.DataFrame({'product_id': productos_unicos})\n",
        "    semanas_unicas_df = pd.DataFrame({'semana': semanas_unicas})\n",
        "    aÃ±o_unicos_df = pd.DataFrame({'aÃ±o': aÃ±o_unicos})\n",
        "\n",
        "    combinaciones = customer_unicos_df.merge(productos_unicos_df, how='cross')\n",
        "    combinaciones = combinaciones.merge(semanas_unicas_df, how='cross')\n",
        "    combinaciones = combinaciones.merge(aÃ±o_unicos_df, how='cross')\n",
        "\n",
        "#se une con el dataset agrupado\n",
        "    data = combinaciones.merge(df_agrupado, on=['customer_id', 'product_id', 'semana', 'aÃ±o'], how='left')\n",
        "\n",
        "#creacion label\n",
        "    data['cantidad_order'] = data['cantidad_order'].fillna(0)\n",
        "    data['label'] = (data['cantidad_order'] > 0).astype(int)\n",
        "\n",
        "#union con variables faltantes\n",
        "    data_final = data.merge(data_clientes, on = 'customer_id', how = 'left')\n",
        "    data_final = data_final.merge(data_productos, on = 'product_id', how = 'left')\n",
        "\n",
        "#data_final = data_final[~((data_final['aÃ±o'] == 2025) & (data_final['semana'] > 3))]\n",
        "\n",
        "    data_final = data_final.sort_values(by=['aÃ±o', 'semana'], ascending=[True, True])\n",
        "    valores_reales = data_final[data_final['label'] == 1][['customer_id','product_id']]\n",
        "    output_path = f'valores_true_semana_{semana}.csv'\n",
        "    #valores_reales.to_csv(output_path, index=False)\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cÃ³digo para evaluar el performance de su modelo\n",
        "def evaluar_performance(predicciones, valores_true, semana):\n",
        "\n",
        "    predicciones_semana = pd.read_csv(predicciones, names = [\"customer_id\", \"product_id\"])\n",
        "    predicciones_semana['y_pred'] = 1\n",
        "\n",
        "    valores_reales_semana = pd.read_csv(preprocesamiento_datos(valores_true, semana))\n",
        "    valores_reales_semana['y_true'] = 1\n",
        "\n",
        "    todos_los_pares = predicciones_semana.merge(valores_reales_semana, on=[\"customer_id\", \"product_id\"], how=\"outer\", indicator=True)\n",
        "\n",
        "    todos_los_pares['y_true'].fillna(0, inplace=True)\n",
        "    todos_los_pares['y_pred'].fillna(0, inplace=True)\n",
        "\n",
        "    tp = (todos_los_pares['_merge'] == 'both').sum()\n",
        "    fp = (todos_los_pares['_merge'] == 'left_only').sum()\n",
        "    fn = (todos_los_pares['_merge'] == 'right_only').sum()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"Resultados para la semana {semana}:\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para la semana 1:\n",
            "Precision: 0.0554\n",
            "Recall: 0.7819\n",
            "F1 Score: 0.1034\n"
          ]
        }
      ],
      "source": [
        "evaluar_performance(\"predictions/predicciones_semana_1_2025.csv\", 'data/batch_t1.parquet', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 2 (06/01/25 - 12/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para la semana 2:\n",
            "Precision: 0.2002\n",
            "Recall: 0.4923\n",
            "F1 Score: 0.2846\n"
          ]
        }
      ],
      "source": [
        "evaluar_performance(\"predictions/predicciones_semana_2_2025.csv\", 'data/batch_t2.parquet', 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 03 (13/01/25 - 19/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para la semana 3:\n",
            "Precision: 0.0819\n",
            "Recall: 0.7462\n",
            "F1 Score: 0.1475\n"
          ]
        }
      ],
      "source": [
        "evaluar_performance(\"predictions/predicciones_semana_3_2025.csv\", 'data/batch_t3.parquet', 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ğŸ“Œ Batch 04 (20/01/25 - 26/01/25) [0.75 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados para la semana 4:\n",
            "Precision: 0.0865\n",
            "Recall: 0.7758\n",
            "F1 Score: 0.1557\n"
          ]
        }
      ],
      "source": [
        "evaluar_performance(\"predictions/predicciones_semana_4_2025.csv\", 'data/batch_t4.parquet', 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ AnÃ¡lisis comparativo [2.0 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cÃ³digo para realizar anÃ¡lisis de resultados entre batchs\n",
        "\n",
        "f1_evolucion = [0.1034, 0.2846, 0.1475, 0.1557]\n",
        "recall_evolucion = [0.7819,0.4923, 0.7462, 0.7758]\n",
        "precision_evolcuion = [0.0554,0.2002,0.0819,0.0865]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Œ Conclusiones y Aprendizajes [1.0 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> A lo largo de este proyecto, aprendimos a realizar un modelo de ML desde cero para luego llevarlo a producciÃ³n y monitorearlo de manera periÃ³dica con datos nuevos, en *batches* correspondientes a una nueva semana cada vez. \n",
        ">\n",
        "> Para ello, comenzamos primeramente haciendo una EDA exhaustiva de los datos, que nos permitiÃ³ identificar quÃ© variables eran relevantes y cÃ³mo podÃ­amos modelar el problema. Posteriormente, se realizÃ³ un preprocesamiento de los datos para luego implementar diversos modelos para tratar el problema, donde luego de hacer optimizaciÃ³n de hiperparÃ¡metro con Optuna, se escogiÃ³ el modelo XGBoost para realizar predicciones pues fue el que obtuvo las mejores mÃ©tricas de predicciÃ³n.\n",
        ">\n",
        "> Luego de ello, vino la implementaciÃ³n del pipeline productivo por medio de un DAG de Airflow, que nos permitiÃ³ hacer monitoreo del modelo y la capacidad de automatizar el proceso de recepciÃ³n de informaciÃ³n, preprocesamiento de los datos y generaciÃ³n de predicciones, con la capacidad de reentrenar el modelo en caso de presentarse *data drifting*.\n",
        ">\n",
        "> Finalmente, se realizaron predicciones de horizonte semanal a partir de los nuevos *batches* de datos recibidos correspondientes a una nueva semana. Si bien las mÃ©tricas no fueron las mejores, nos permitieron ver cÃ³mo el modelo se adapta a nuevos datos y capturar cuÃ¡ndo es necesario realizar un reentrenamiento del modelo producto del *data drift*.\n",
        ">\n",
        "> A lo largo del proyecto nos vimos enfrentados a varias dificultades, tanto por capacidad de cÃ³mputo como por la dificultad de algunos puntos del proyecto. En ese contexto, se concluye que el proyecto realizado fue medianamente exitoso en su ejecuciÃ³n, pero nos permitiÃ³ aprender muchos de los pasos necesarios para desarrollar un modelo en contexto real productivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Estructura de entrega\n",
        "\n",
        "Se espera que su entrega cuente con la siguiente estructura de carpetas:\n",
        "\n",
        "```bash\n",
        "entrega_3/\n",
        "â”‚\n",
        "â”œâ”€â”€ informe.ipynb # Jupyter notebook con sus resultados\n",
        "â”‚\n",
        "â”œâ”€â”€ predictions/ # Carpeta con las predicciones para cada batch de datos\n",
        "â”‚\n",
        "â””â”€â”€ data/ # Carpeta con los datos realizados (lo que realmente ocurriÃ³)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM6rrqJ85tmz"
      },
      "source": [
        "Mucho Ã©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://gifdb.com/images/high/may-the-force-be-with-you-anakin-skywalker-n2g5o0pm4h6iylsx.gif\" width=\"400\" height=\"300\">\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_app_layout": "powerful-article",
    "deepnote_app_reactivity_enabled": true,
    "deepnote_notebook_id": "2939a76dd7c14f7f948714e40aa8bd20",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
